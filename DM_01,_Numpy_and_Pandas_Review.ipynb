{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8dd57d88",
      "metadata": {
        "id": "8dd57d88"
      },
      "source": [
        "We give an overview of two Python libraries that are very commonly used in machine learning applications: numpy and pandas.\n",
        "\n",
        "First, you need to make sure that they are installed in the environment you are working on. You can uncomment (delete the #) and run the following cell to install them for now, but we'd like you to have an environment setup for all of your Data Mine work so that you do not need to re-install all packages you use every time (there will be more than just these two). If you are not familiar with creating conda environments, this is a great task to accomplish during your first lab, so that your TAs can walk you through it step by step. Instructions on how to do so on Anvil can also be found here: https://www.rcac.purdue.edu/knowledge/Anvil/run/examples/apps/python/packages However, this process can be tricky if you have never done it before, so don't get discouraged, get someone to help you, and just get it set up. It can be a little tedious, but things are way more fun once this step is done.\n",
        "\n",
        "If you installed pandas and numpy in your environment, you won't need to do it again, so we commented the next cell.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06dcba62",
      "metadata": {
        "id": "06dcba62"
      },
      "outputs": [],
      "source": [
        "# pip install numpy\n",
        "# pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2dcc2de",
      "metadata": {
        "id": "b2dcc2de"
      },
      "source": [
        "Once a library is installed, it is sufficient to import it to be able to use it for the rest of the notebook. We can simply import a package (for example, typing \"import numpy\"), or we can import it and give it a shorthand that we can refer to it by later on. Usually we shorten numpy by np and pandas by pd. This means that every time we want to reference them later on we can just use np and pd. In the long run this makes things faster and easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab01d953",
      "metadata": {
        "id": "ab01d953"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our libraries available, let's see what we can do with them. We will begin with numpy."
      ],
      "metadata": {
        "id": "cIIZh5wsY7Nh"
      },
      "id": "cIIZh5wsY7Nh"
    },
    {
      "cell_type": "markdown",
      "id": "4cc4551a",
      "metadata": {
        "id": "4cc4551a"
      },
      "source": [
        "## Numpy\n",
        "\n",
        "Numpy is used to deal with arrays of numbers. These are useful if we want to store numerical data. For example, suppose I want to store data relative to the average temperature in West Lafayette every day for the past week. We will first store this data as a Python list, and then convert it to a numpy array. As I'm writing this in December, this may look something like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40ca32b",
      "metadata": {
        "id": "f40ca32b"
      },
      "outputs": [],
      "source": [
        "# create a list of values\n",
        "temperature_list = [29, 32, 25, 30, 34, 37, 41]\n",
        "\n",
        "# convert the list to a numpy array\n",
        "temperature_array = np.array(temperature_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2875721a",
      "metadata": {
        "id": "2875721a"
      },
      "source": [
        "Having converted our list to an array, we can use numpy built in functions to answer questions about our numerical list, such as what was the maximum temperature recorded? What was the minimum? What was the average over all seven days? There are more built in functions that one can use with numpy. A full list can be found here: https://numpy.org/doc/stable/reference/routines.math.html\n",
        "Most of us don't have all of these memorized, and neither are you expected to, but it is good to get a sense for what's available, so that when you need to use a function you can look up the precise syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58a5d15",
      "metadata": {
        "id": "b58a5d15"
      },
      "outputs": [],
      "source": [
        "# what's the maximum temperature in the array?\n",
        "np.max(temperature_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a46d5a3",
      "metadata": {
        "id": "9a46d5a3"
      },
      "outputs": [],
      "source": [
        "# what's the minimum temperature in the array?\n",
        "np.min(temperature_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc20407",
      "metadata": {
        "id": "8dc20407"
      },
      "outputs": [],
      "source": [
        "# what's the average temperature in the array?\n",
        "np.average(temperature_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2c79aa",
      "metadata": {
        "id": "cd2c79aa"
      },
      "source": [
        "Referencing the list of functions above, try to answer the following questions yourself, using numpy built in functions when useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39823f6",
      "metadata": {
        "id": "d39823f6"
      },
      "outputs": [],
      "source": [
        "# Q1: what's the sum of all temperatures in the array?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef57f9e",
      "metadata": {
        "id": "aef57f9e"
      },
      "outputs": [],
      "source": [
        "# Q2 : given that the formula to conver Fahrenheit to Celsius is\n",
        "# °C = (°F - 32) × 5/9, and that you can apply a formula to an entire array\n",
        "# at once, convert the temperature array from °F to °C."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53fb122",
      "metadata": {
        "id": "d53fb122"
      },
      "source": [
        "We can create arrays with multiple rows too. For example, suppose we want to record the average temperatures for the last three weeks. We may use the following array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c880abea",
      "metadata": {
        "id": "c880abea"
      },
      "outputs": [],
      "source": [
        "temp_3_week = np.array([[40, 45, 43, 37, 32, 35, 38],\n",
        "                       [41, 43, 44, 40, 37, 33, 31],\n",
        "                       [29, 32, 25, 30, 34, 37, 41]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2aef6d3",
      "metadata": {
        "id": "e2aef6d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25b585d-7464-4484-d19e-fe5ca621d8b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 45, 43, 37, 32, 35, 38],\n",
              "       [41, 43, 44, 40, 37, 33, 31],\n",
              "       [29, 32, 25, 30, 34, 37, 41]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# let's display it\n",
        "temp_3_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc36c6a",
      "metadata": {
        "id": "bbc36c6a"
      },
      "outputs": [],
      "source": [
        "# Q3: use the same method as above to compute maximum, minimum, average,\n",
        "# sum of all entries and to convert it to Celsius"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12566fc",
      "metadata": {
        "id": "c12566fc"
      },
      "source": [
        "Arrays have an attribute called shape that tells us the number of rows and columns in them. For example, here are the shapes of the two arrays we've used so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f13e901e",
      "metadata": {
        "id": "f13e901e"
      },
      "outputs": [],
      "source": [
        "temperature_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946cc989",
      "metadata": {
        "id": "946cc989"
      },
      "outputs": [],
      "source": [
        "temp_3_week.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd946262",
      "metadata": {
        "id": "cd946262"
      },
      "source": [
        "The total number of elements in an array is its size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9a96f6",
      "metadata": {
        "id": "bd9a96f6"
      },
      "outputs": [],
      "source": [
        "temperature_array.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f29c009",
      "metadata": {
        "id": "1f29c009"
      },
      "outputs": [],
      "source": [
        "temp_3_week.size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55a79df8",
      "metadata": {
        "id": "55a79df8"
      },
      "source": [
        "You may read up here (https://numpy.org/doc/stable/user/quickstart.html) on how to initialize arrays. After reading this page, you should be able to answer the following questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e886784",
      "metadata": {
        "id": "9e886784"
      },
      "outputs": [],
      "source": [
        "# Q4: create an array of zeros with 4 rows and 3 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3034f58",
      "metadata": {
        "id": "c3034f58"
      },
      "outputs": [],
      "source": [
        "# Q5: create an array of ones with 2 rows and 16 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9e8b50",
      "metadata": {
        "id": "bb9e8b50"
      },
      "outputs": [],
      "source": [
        "# Q6: create an array with random entries with 6 rows and 2 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff86e5da",
      "metadata": {
        "id": "ff86e5da"
      },
      "outputs": [],
      "source": [
        "# Q7: create an array with 4 entries consisting of\n",
        "# evenly spaced integers between 2 and 8 included"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ade607",
      "metadata": {
        "id": "43ade607"
      },
      "source": [
        "As we conclude our brief overview of numpy, we look at one last feature of this library. It is sometimes convenient to look at arrays of arrays. For example, we might want to consider an object that looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0a2339e",
      "metadata": {
        "id": "d0a2339e"
      },
      "outputs": [],
      "source": [
        "example_array = np.random.rand(2, 3, 4)\n",
        "example_array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19330ce",
      "metadata": {
        "id": "a19330ce"
      },
      "source": [
        "This created two arrays, with three rows and four columns each, which together form a unique numpy object. If we want to look at a particular entry of an array, we can use the following notation to extract it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebce67e",
      "metadata": {
        "id": "3ebce67e"
      },
      "outputs": [],
      "source": [
        "# extract the first entry of the temperature_array\n",
        "# remember that Python starts counting at 0\n",
        "\n",
        "temperature_array[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97ffdf9",
      "metadata": {
        "id": "a97ffdf9"
      },
      "outputs": [],
      "source": [
        "# extract the temperature of the fourth day of the second week in the\n",
        "# temp_3_week array\n",
        "\n",
        "temp_3_week[1][3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8292505d",
      "metadata": {
        "id": "8292505d"
      },
      "outputs": [],
      "source": [
        "# extract the temperature of the last day of the third week in the\n",
        "# temp_3_week array\n",
        "\n",
        "temp_3_week[-1][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94821be",
      "metadata": {
        "id": "a94821be"
      },
      "outputs": [],
      "source": [
        "# we could also have used\n",
        "temp_3_week[2][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f952d58",
      "metadata": {
        "id": "9f952d58"
      },
      "outputs": [],
      "source": [
        "# Q8: extract the object in the second array, third row, fourth\n",
        "# column of the example_array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas"
      ],
      "metadata": {
        "id": "JPIPHCrPbiMW"
      },
      "id": "JPIPHCrPbiMW"
    },
    {
      "cell_type": "markdown",
      "id": "d74c723a",
      "metadata": {
        "id": "d74c723a"
      },
      "source": [
        "Sometimes we will want to consider datasets larger than just one array, and that's where it's often convenient to use the pandas library. As a first step in that direction, let us load a famous dataset from a library called sklearn. Again, you may need to install it first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85aaa7cf",
      "metadata": {
        "id": "85aaa7cf"
      },
      "outputs": [],
      "source": [
        "# pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43704ff1",
      "metadata": {
        "id": "43704ff1"
      },
      "outputs": [],
      "source": [
        "# import sklearn\n",
        "import sklearn\n",
        "\n",
        "# import the library that allows us to load the dataset we will use, called iris\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca55718",
      "metadata": {
        "id": "dca55718"
      },
      "outputs": [],
      "source": [
        "# now we can call the load_iris() function to import the dataset\n",
        "# we give it the name iris_data\n",
        "iris_data = load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c956ed",
      "metadata": {
        "id": "50c956ed"
      },
      "source": [
        "You'll find a description of the iris dataset here: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
        "\n",
        "We could have a look at the data contained in it just by doing the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16762b84",
      "metadata": {
        "id": "16762b84"
      },
      "outputs": [],
      "source": [
        "# display the data we just imported\n",
        "iris_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b7477d",
      "metadata": {
        "id": "58b7477d"
      },
      "source": [
        "Take a look at that output. You should find confirmation of what you read on the page we linked above. For example, you should have read that this dataset consists of 150 samples with 5 attributes each. The first four attributes, usually referred to as input features, are numerical measures of four characteristics of types of flowers: sepal length, sepal width, petal length, petal width. The fifth value, usually referred to as target, is a classification of the flower mesured in that row into one of three possible classes: setosa, versicolor, or virginica. These are encoded as 0 for setosa, 1 for versicolor, and 2 for virginica.\n",
        "\n",
        "For example, let's consider the first row of the data set. We use \".data\" to extract the four numerical columns and \".target\" to extract the target. Then we single out which row we'd like to access using the same notation with square brackets that we encountered above, since data and target are arrays. We'll see the four measurement and a value of 0 for the target, meaning that this flower is a setosa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078f4631",
      "metadata": {
        "id": "078f4631"
      },
      "outputs": [],
      "source": [
        "print(iris_data.data[0])\n",
        "print(iris_data.target[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84bf1ee8",
      "metadata": {
        "id": "84bf1ee8"
      },
      "source": [
        "An alternative way to visualize this dataset can be to use pandas. Pandas allows to store data in a structure called a data frame. Our goal is to create a data frame with five columns, one for each of sepal length, sepal width, petal length, petal width, and target. We begin by combining the arrays for the input features and the target into a single array called all_iris_data. We use the numpy function concatenate to do so. You find this function's syntax here: https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html\n",
        "If we simply try to concatenate the two arrays, we get an error message telling us that the input arrays don't have the same dimensions. Let's try."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ac2148",
      "metadata": {
        "id": "33ac2148"
      },
      "outputs": [],
      "source": [
        "all_iris_data = np.concatenate((iris_data.data, iris_data.target), axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7522bb5f",
      "metadata": {
        "id": "7522bb5f"
      },
      "source": [
        "Let's inspect the dimensions of our arrays as we learnt above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86562ebb",
      "metadata": {
        "id": "86562ebb"
      },
      "outputs": [],
      "source": [
        "iris_data.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea56ef8a",
      "metadata": {
        "id": "ea56ef8a"
      },
      "outputs": [],
      "source": [
        "iris_data.target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c3201f",
      "metadata": {
        "id": "e7c3201f"
      },
      "source": [
        "It appears that the issue is that the target aray is seen just as a list of values instead of a 150 x 1 matrix. Luckily, there's an easy fix: we use the numpy function reshape (more on it here: https://numpy.org/doc/stable/reference/generated/numpy.reshape.html). We'll then be able to join the arrays as we were trying to do before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe55416",
      "metadata": {
        "id": "cfe55416"
      },
      "outputs": [],
      "source": [
        "target_data = np.reshape(iris_data.target, (150, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6418e54f",
      "metadata": {
        "id": "6418e54f"
      },
      "outputs": [],
      "source": [
        "# let's check that the shape of this new array is the desired one\n",
        "target_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3604732c",
      "metadata": {
        "id": "3604732c"
      },
      "outputs": [],
      "source": [
        "# we can now join the two arrays\n",
        "all_iris_data = np.concatenate((iris_data.data, target_data), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faaf3a46",
      "metadata": {
        "id": "faaf3a46"
      },
      "outputs": [],
      "source": [
        "# let's display our new array\n",
        "all_iris_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ac4f1a",
      "metadata": {
        "id": "76ac4f1a"
      },
      "source": [
        "We can now convert our dataset into a data frame. We will need to assign names to the columns of the data frame. We'll use sepal length, sepal width, petal length, petal width, target as our five column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d50431f",
      "metadata": {
        "id": "4d50431f"
      },
      "outputs": [],
      "source": [
        "iris_df = pd.DataFrame(all_iris_data,\n",
        "                       columns = ['sepal length', 'sepal width',\n",
        "                                  'petal length', 'petal width', 'target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f65be78",
      "metadata": {
        "id": "7f65be78"
      },
      "outputs": [],
      "source": [
        "# let's display the data frame we just created\n",
        "iris_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f791d169",
      "metadata": {
        "id": "f791d169"
      },
      "source": [
        "There are a lot of operations one can perform on a data frame. I'd recommend taking a look at this page (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) outlining several of them to get an idea for what we can do with them. Maybe try out a few yourself usign the data frame we just created. For example, with the help of this webpage, you shuold be able to answer the following questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803e2847",
      "metadata": {
        "id": "803e2847"
      },
      "outputs": [],
      "source": [
        "# Q9: a) print the names of the columns of the data frame\n",
        "# b) display row 48 to 55 of the data frame\n",
        "# c) display column 'petal width'\n",
        "# d) create a new data frame called test_df that only contains\n",
        "# the first three columns of iris_df\n",
        "# e) display the first 7 rows of the data frame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcd9bfe",
      "metadata": {
        "id": "cbcd9bfe"
      },
      "source": [
        "You've reached the end of our first notebook. Please don't be afraid to reach out to your TAs or your more experienced classmates if anything is not clear: they'll be happy to help make sure that the whole team is familiar with these concepts before we move on.\n",
        "\n",
        "Our next task will be to use the input columns of the iris data frame to predict the target value using a basic machine learning algorithm. If you're already familiar with these ideas, give it a try yourself before checking out our approach. As is very often the case in machine learning, many different approaches are possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9750c57",
      "metadata": {
        "id": "e9750c57"
      },
      "outputs": [],
      "source": [
        "# ANS1:\n",
        "# np.sum(temperature_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5f90d8",
      "metadata": {
        "id": "cc5f90d8"
      },
      "outputs": [],
      "source": [
        "# ANS2:\n",
        "#temp_array_C = (temperature_array - 32)*5/9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a303ae84",
      "metadata": {
        "id": "a303ae84"
      },
      "outputs": [],
      "source": [
        "# ANS3:\n",
        "# maximum3weeks = np.max(temp_3_week)\n",
        "# minimum3weeks = np.min(temp_3_week)\n",
        "# average3weeks = np.average(temp_3_week)\n",
        "# sum3weeks = np.sum(temp_3_week)\n",
        "# celsius3weeks = (temp_3_week - 32)*5/9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "313d8eb8",
      "metadata": {
        "id": "313d8eb8"
      },
      "outputs": [],
      "source": [
        "# ANS4:\n",
        "# np.zeros((4, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a3c6a4",
      "metadata": {
        "id": "b9a3c6a4"
      },
      "outputs": [],
      "source": [
        "# ANS5:\n",
        "# np.ones((2, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a02fac",
      "metadata": {
        "id": "55a02fac"
      },
      "outputs": [],
      "source": [
        "# ANS6:\n",
        "# np.random.rand(2, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea84cbfe",
      "metadata": {
        "id": "ea84cbfe"
      },
      "outputs": [],
      "source": [
        "# ANS7:\n",
        "# np.arange(2, 10, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01bfc484",
      "metadata": {
        "id": "01bfc484"
      },
      "outputs": [],
      "source": [
        "# ANS8:\n",
        "# example_array[1][2][3]\n",
        "\n",
        "# alternatively,\n",
        "#example_array[-1][-1][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9703b410",
      "metadata": {
        "id": "9703b410"
      },
      "outputs": [],
      "source": [
        "# ANS9:\n",
        "# a)\n",
        "# iris_df.columns\n",
        "# b)\n",
        "# iris_df.iloc[48:56]\n",
        "# c)\n",
        "# iris_df['petal width']\n",
        "# d) several solutions are possible. One example:\n",
        "# test_df = iris_df.drop(columns=['petal width', 'target'])\n",
        "# e)\n",
        "# iris_df.head(7)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8 - Learning [learning/conda-2020.11-py38-gpu]",
      "language": "python",
      "name": "sys_learning38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}